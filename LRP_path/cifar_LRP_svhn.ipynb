{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "%matplotlib inline\n",
    "\n",
    "from innvestigator import InnvestigateModel\n",
    "from inverter_util import Flatten\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "from VGG_16 import VGG16\n",
    "import pickle\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2560\n",
    "transform_train = transforms.Compose([\n",
    "#             transforms.RandomCrop(32, padding=4),\n",
    "#             transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor()\n",
    "    ])\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "])\n",
    "train_data = torchvision.datasets.SVHN(\n",
    "        root = './data/svhn',\n",
    "        split = 'train',\n",
    "        transform = transform_train,\n",
    "        download = False\n",
    ")\n",
    "test_data = torchvision.datasets.SVHN(\n",
    "        root = './data/svhn',\n",
    "        split = 'test',\n",
    "        transform = transform_test,\n",
    "        download = False)\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=batch_size, shuffle=False)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "def pick_neurons_layer(relev, per=0.1): \n",
    "    rel = torch.sum(relev, [2, 3])\n",
    "    _, units = torch.topk(rel, round(per*rel.size(1)), dim=1)\n",
    "    print(units.shape)\n",
    "    return units.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "index: 1\n",
      "index: 2\n",
      "index: 3\n",
      "index: 4\n",
      "index: 5\n",
      "index: 6\n",
      "index: 7\n",
      "index: 8\n",
      "index: 9\n"
     ]
    }
   ],
   "source": [
    "seeds = [32]\n",
    "dropouts = [True]\n",
    "\n",
    "classes = list(range(10))\n",
    "\n",
    "path_class = {}\n",
    "for i in classes:\n",
    "    path_class[i] = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seed in seeds:\n",
    "        for dropout in dropouts:\n",
    "            model = VGG16(num_classes=10)\n",
    "            if dropout:\n",
    "                model_path = \"../vgg_seed\" + str(seed) + \"_dropout.pkl\"\n",
    "            else:\n",
    "                model_path = \"../vgg_seed\" + str(seed) + \"_nodropout.pkl\"\n",
    "            checkpoint = torch.load(model_path)\n",
    "            model.load_state_dict(checkpoint)\n",
    "            model = model.cuda()\n",
    "            model.eval()\n",
    "                        # Convert to innvestigate model\n",
    "            inn_model = InnvestigateModel(model, lrp_exponent=2,\n",
    "                                          method=\"e-rule\",\n",
    "                                          beta=.5)\n",
    "            for i, (data, target) in enumerate(train_loader):\n",
    "\n",
    "                print(\"index:\", i)\n",
    "\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                batch_size = int(data.size()[0])\n",
    "\n",
    "                model_prediction, _ , true_relevance = inn_model.innvestigate(in_tensor=data)\n",
    "                \n",
    "                _, train_pred_y = model_prediction.max(1)\n",
    "                if i == 0:\n",
    "                    labels = train_pred_y\n",
    "                labels = torch.cat((labels, train_pred_y), 0)\n",
    "\n",
    "                if i == 0:\n",
    "                    relev = true_relevance\n",
    "                else:\n",
    "                    for l in range(len(relev)):\n",
    "                        relev[l] = torch.cat((relev[l], true_relevance[l]), 0)\n",
    "                        \n",
    "            \n",
    "            pers = [0.1, 1.0]\n",
    "            for per in pers:\n",
    "                sample_neurons = {}\n",
    "                for layer in range(len(relev)):\n",
    "                    true_layer = 12-layer\n",
    "                    r = relev[true_layer]\n",
    "                    units = pick_neurons_layer(r, per)\n",
    "                    for i in range(units.shape[0]):\n",
    "                        if layer == 0:\n",
    "                            sample_neurons[i] = []\n",
    "                        sample_neurons[i].append(units[i])\n",
    "                if dropout:\n",
    "                    save_path = \"./lrp_path_\" + str(per) + \"_seed\" + str(seed) + \"_train_SVHN\" + \".pkl\"\n",
    "                    \n",
    "                else:\n",
    "                    save_path = \"./lrp_path_\" + str(per) + \"_seed\" + str(seed) + \"_train_nodropout_SVHN\" \n",
    "                    + \".pkl\"\n",
    "                    \n",
    "                labels_path = \"../paths/svhn_labels_seed32.pkl\"\n",
    "                output = open(save_path, 'wb')\n",
    "                pickle.dump(sample_neurons, output) \n",
    "                labels_out = open(labels_path, 'wb')\n",
    "                pickle.dump(labels, labels_out) \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "index: 1\n",
      "index: 2\n",
      "index: 3\n",
      "index: 4\n",
      "index: 5\n",
      "index: 6\n",
      "index: 7\n",
      "index: 8\n",
      "index: 9\n",
      "index: 10\n",
      "torch.Size([26032, 6])\n",
      "torch.Size([26032, 6])\n",
      "torch.Size([26032, 13])\n",
      "torch.Size([26032, 13])\n",
      "torch.Size([26032, 26])\n",
      "torch.Size([26032, 26])\n",
      "torch.Size([26032, 26])\n",
      "torch.Size([26032, 51])\n",
      "torch.Size([26032, 51])\n",
      "torch.Size([26032, 51])\n",
      "torch.Size([26032, 51])\n",
      "torch.Size([26032, 51])\n",
      "torch.Size([26032, 51])\n",
      "torch.Size([26032, 64])\n",
      "torch.Size([26032, 64])\n",
      "torch.Size([26032, 128])\n",
      "torch.Size([26032, 128])\n",
      "torch.Size([26032, 256])\n",
      "torch.Size([26032, 256])\n",
      "torch.Size([26032, 256])\n",
      "torch.Size([26032, 512])\n",
      "torch.Size([26032, 512])\n",
      "torch.Size([26032, 512])\n",
      "torch.Size([26032, 512])\n",
      "torch.Size([26032, 512])\n",
      "torch.Size([26032, 512])\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "seeds = [32]\n",
    "dropouts = [True]\n",
    "\n",
    "classes = list(range(10))\n",
    "\n",
    "path_class = {}\n",
    "for i in classes:\n",
    "    path_class[i] = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for seed in seeds:\n",
    "        for dropout in dropouts:\n",
    "            model = VGG16(num_classes=10)\n",
    "            if dropout:\n",
    "                model_path = \"../vgg_seed\" + str(seed) + \"_dropout.pkl\"\n",
    "            else:\n",
    "                model_path = \"../vgg_seed\" + str(seed) + \"_nodropout.pkl\"\n",
    "            checkpoint = torch.load(model_path)\n",
    "            model.load_state_dict(checkpoint)\n",
    "            model = model.cuda()\n",
    "            model.eval()\n",
    "                        # Convert to innvestigate model\n",
    "            inn_model = InnvestigateModel(model, lrp_exponent=2,\n",
    "                                          method=\"e-rule\",\n",
    "                                          beta=.5)\n",
    "            for i, (data, target) in enumerate(test_loader):\n",
    "\n",
    "                print(\"index:\", i)\n",
    "\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                batch_size = int(data.size()[0])\n",
    "\n",
    "                model_prediction, _ , true_relevance = inn_model.innvestigate(in_tensor=data)\n",
    "                \n",
    "                _, train_pred_y = model_prediction.max(1)\n",
    "                if i == 0:\n",
    "                    labels = train_pred_y\n",
    "                else:\n",
    "                    labels = torch.cat((labels, train_pred_y), 0)\n",
    "\n",
    "                if i == 0:\n",
    "                    relev = true_relevance\n",
    "                else:\n",
    "                    for l in range(len(relev)):\n",
    "                        relev[l] = torch.cat((relev[l], true_relevance[l]), 0)\n",
    "                        \n",
    "            \n",
    "            pers = [0.1, 1.0]\n",
    "            for per in pers:\n",
    "                sample_neurons = {}\n",
    "                for layer in range(len(relev)):\n",
    "                    true_layer = 12-layer\n",
    "                    r = relev[true_layer]\n",
    "                    units = pick_neurons_layer(r, per)\n",
    "                    for i in range(units.shape[0]):\n",
    "                        if layer == 0:\n",
    "                            sample_neurons[i] = []\n",
    "                        sample_neurons[i].append(units[i])\n",
    "                if dropout:\n",
    "                    save_path = \"./lrp_path_\" + str(per) + \"_seed\" + str(seed) + \"_test_SVHN\" + \".pkl\"\n",
    "                    \n",
    "                else:\n",
    "                    save_path = \"./lrp_path_\" + str(per) + \"_seed\" + str(seed) + \"_test_nodropout_SVHN\" \n",
    "                    + \".pkl\"\n",
    "                    \n",
    "                labels_path = \"../paths/svhn_labels_seed32_test.pkl\"\n",
    "                output = open(save_path, 'wb')\n",
    "                pickle.dump(sample_neurons, output) \n",
    "                labels_out = open(labels_path, 'wb')\n",
    "                pickle.dump(labels, labels_out) \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for test_step, (val_x, val_y) in enumerate(test_loader):\n",
    "        print(\"step:\", test_step)\n",
    "        val_x = val_x.cuda()\n",
    "        val_y = val_y.cuda()\n",
    "        val_output = model(val_x)\n",
    "        _, val_pred_y = val_output.max(1)\n",
    "        if test_step == 0:\n",
    "            correct = val_pred_y.eq(val_y).sum().item()\n",
    "        else:\n",
    "            correct += val_pred_y.eq(val_y).sum().item()\n",
    "        total += val_y.size(0)\n",
    "result = float(correct) * 100.0 / float(total)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "index: 1\n",
      "index: 2\n",
      "index: 3\n",
      "done\n",
      "13\n"
     ]
    }
   ],
   "source": [
    " for i, (data, target) in enumerate(test_loader):\n",
    "    \n",
    "    print(\"index:\", i)\n",
    "\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    batch_size = int(data.size()[0])\n",
    "\n",
    "    model_prediction, _ , true_relevance = inn_model.innvestigate(in_tensor=data)\n",
    "    \n",
    "    if i == 0:\n",
    "        relev = true_relevance\n",
    "    else:\n",
    "        for l in range(len(relev)):\n",
    "            relev[l] = torch.cat((relev[l], true_relevance[l]), 0)\n",
    "\n",
    "print(\"done\")\n",
    "print(len(relev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 1])\n",
      "torch.Size([10000, 3])\n",
      "torch.Size([10000, 3])\n",
      "torch.Size([10000, 3])\n",
      "torch.Size([10000, 5])\n",
      "torch.Size([10000, 5])\n",
      "torch.Size([10000, 5])\n",
      "torch.Size([10000, 5])\n",
      "torch.Size([10000, 5])\n",
      "torch.Size([10000, 5])\n",
      "torch.Size([10000, 2])\n",
      "torch.Size([10000, 2])\n",
      "torch.Size([10000, 4])\n",
      "torch.Size([10000, 4])\n",
      "torch.Size([10000, 8])\n",
      "torch.Size([10000, 8])\n",
      "torch.Size([10000, 8])\n",
      "torch.Size([10000, 15])\n",
      "torch.Size([10000, 15])\n",
      "torch.Size([10000, 15])\n",
      "torch.Size([10000, 15])\n",
      "torch.Size([10000, 15])\n",
      "torch.Size([10000, 15])\n",
      "torch.Size([10000, 3])\n",
      "torch.Size([10000, 3])\n",
      "torch.Size([10000, 6])\n",
      "torch.Size([10000, 6])\n",
      "torch.Size([10000, 13])\n",
      "torch.Size([10000, 13])\n",
      "torch.Size([10000, 13])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 6])\n",
      "torch.Size([10000, 6])\n",
      "torch.Size([10000, 13])\n",
      "torch.Size([10000, 13])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 51])\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "pers = [0.01, 0.03, 0.05, 0.1]\n",
    "for per in pers:\n",
    "    sample_neurons = {}\n",
    "    for layer in range(len(relev)):\n",
    "        true_layer = 12-layer\n",
    "        r = relev[true_layer]\n",
    "        units = pick_neurons_layer(r, per)\n",
    "        for i in range(units.shape[0]):\n",
    "            if layer == 0:\n",
    "                sample_neurons[i] = []\n",
    "            sample_neurons[i].append(units[i])\n",
    "\n",
    "    save_path = \"./lrp_path_\" + str(per) + \"_seed\" + str(seed) +  \"_test.pkl\"\n",
    "    output = open(save_path, 'wb')\n",
    "    pickle.dump(sample_neurons, output)  \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index: 0\n",
      "index: 1\n",
      "index: 2\n",
      "index: 3\n",
      "done\n",
      "13\n",
      "torch.Size([10000, 6])\n",
      "torch.Size([10000, 6])\n",
      "torch.Size([10000, 13])\n",
      "torch.Size([10000, 13])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 26])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 51])\n",
      "torch.Size([10000, 64])\n",
      "torch.Size([10000, 64])\n",
      "torch.Size([10000, 128])\n",
      "torch.Size([10000, 128])\n",
      "torch.Size([10000, 256])\n",
      "torch.Size([10000, 256])\n",
      "torch.Size([10000, 256])\n",
      "torch.Size([10000, 512])\n",
      "torch.Size([10000, 512])\n",
      "torch.Size([10000, 512])\n",
      "torch.Size([10000, 512])\n",
      "torch.Size([10000, 512])\n",
      "torch.Size([10000, 512])\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "batch_size = 2560\n",
    "attack = \"pgd\"\n",
    "seed = 32\n",
    "model = VGG16(num_classes=10)\n",
    "\n",
    "model_path = \"../vgg_seed\" + str(seed) + \"_dropout.pkl\"\n",
    "\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "inn_model = InnvestigateModel(model, lrp_exponent=2,\n",
    "                                          method=\"e-rule\",\n",
    "                                          beta=.5)\n",
    "\n",
    "def read_data_label(data_path, label_path):\n",
    "    with open(data_path, 'rb') as fr:\n",
    "        test_data = pickle.load(fr)\n",
    "        size = len(test_data)\n",
    "    with open(label_path, 'rb') as fr:\n",
    "        test_label = pickle.load(fr)\n",
    "    return test_data, test_label, size\n",
    "\n",
    "def pick_neurons_layer(relev, per=0.1): \n",
    "    rel = torch.sum(relev, [2, 3])\n",
    "    _, units = torch.topk(rel, round(per*rel.size(1)), dim=1)\n",
    "    print(units.shape)\n",
    "    return units.numpy()\n",
    "\n",
    "if attack == \"pgd\":\n",
    "    test_data_path = \"../data/adversarial_samples/Vanilla/pgd/test_adv(eps_0.031).pkl\"\n",
    "    test_label_path = \"../data/adversarial_samples/Vanilla/pgd/test_label.pkl\"\n",
    "    test_data, test_label, size = read_data_label(test_data_path, test_label_path)\n",
    "    dataset = Data.TensorDataset(test_data, test_label)\n",
    "    \n",
    "data_loader = Data.DataLoader(dataset=dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "for i, (data, target) in enumerate(data_loader):\n",
    "    \n",
    "    print(\"index:\", i)\n",
    "\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    batch_size = int(data.size()[0])\n",
    "\n",
    "    model_prediction, _ , true_relevance = inn_model.innvestigate(in_tensor=data)\n",
    "    _, train_pred_y = model_prediction.max(1)\n",
    "    \n",
    "    if i == 0:\n",
    "        labels = train_pred_y\n",
    "    else:\n",
    "        labels = torch.cat((labels, train_pred_y), 0)\n",
    "        \n",
    "    if i == 0:\n",
    "        relev = true_relevance\n",
    "    else:\n",
    "        for l in range(len(relev)):\n",
    "            relev[l] = torch.cat((relev[l], true_relevance[l]), 0)\n",
    "\n",
    "print(\"done\")\n",
    "print(len(relev))\n",
    "\n",
    "pers = [0.1, 1.0]\n",
    "for per in pers:\n",
    "    sample_neurons = {}\n",
    "    for layer in range(len(relev)):\n",
    "        true_layer = 12-layer\n",
    "        r = relev[true_layer]\n",
    "        units = pick_neurons_layer(r, per)\n",
    "        for i in range(units.shape[0]):\n",
    "            if layer == 0:\n",
    "                sample_neurons[i] = []\n",
    "            sample_neurons[i].append(units[i])\n",
    "            \n",
    "    save_path = \"./lrp_path_\" + str(per) + \"_seed\" + str(seed) + \"_adv.pkl\"\n",
    "    \n",
    "    labels_path = \"../paths/svhn_labels_seed32_adv.pkl\"\n",
    "    output = open(save_path, 'wb')\n",
    "    pickle.dump(sample_neurons, output) \n",
    "    labels_out = open(labels_path, 'wb')\n",
    "    pickle.dump(labels, labels_out)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F627AD95A10>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from innvestigator import InnvestigateModel\n",
    "from inverter_util import Flatten\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "from VGG_16 import VGG16\n",
    "import pickle\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "        transforms.ToTensor()\n",
    "])\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "        root = './data/cifar-10',\n",
    "        train = False,\n",
    "#         transform = transform_test,\n",
    "        download = False)\n",
    "print(test_data[0][0])\n",
    "plt.imshow(test_data[0][0])\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.Image.Image image mode=RGB size=32x32 at 0x7F5FAE5E4A50>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "\n",
    "adv_data_path = \"../adv_samples/adv_{}_cifar10_samples.npy\".format(\"pgd\")\n",
    "adv_label_path = \"../adv_samples/adv_{}_cifar10_labels.npy\".format(\"fgsm\")\n",
    "\n",
    "test_data = torch.FloatTensor(np.load(adv_data_path).transpose(0,3,1,2)*255)\n",
    "# dataset = Data.TensorDataset(test_data, test_label)\n",
    "# a = Image.fromarray(test_data[0], mode='RGB')\n",
    "a = transforms.ToPILImage()(test_data[0])\n",
    "print(a)\n",
    "plt.imshow(a)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
