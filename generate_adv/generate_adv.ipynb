{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "\n",
    "import numpy as np\n",
    "from foolbox.models import PyTorchModel\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import torchvision.transforms as T\n",
    "from torch.utils.data import DataLoader\n",
    "from models.VGG_16 import VGG16\n",
    "import torchvision\n",
    "from models.AlexNet_SVHN import AlexNet\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "from generate_utils import generate_adv_version2\n",
    "import torch.utils.data as Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'MyModels'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-99d6163bf05a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mMyModels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerate_Model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_resume_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_featureSize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mMyDatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGenerate_Dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m transform_test = T.Compose([\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'MyModels'"
     ]
    }
   ],
   "source": [
    "sys.path.append(\"../\")\n",
    "from MyModels import Generate_Model, load_resume_model, get_featureSize\n",
    "from MyDatasets import Generate_Dataset\n",
    "\n",
    "transform_test = T.Compose([\n",
    "            T.ToTensor()\n",
    "])\n",
    "\n",
    "test_data = torchvision.datasets.CIFAR10(\n",
    "    root = '../../Dataset/cifar-10',\n",
    "    train = False,\n",
    "    transform = transform_test,\n",
    "    download = False\n",
    ")\n",
    "\n",
    "dataloader = Data.DataLoader(dataset=test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Generate_Model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-3df243575a87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerate_Model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cifar10\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"vgg16_bn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_resume_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cifar10\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"vgg16_bn\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Generate_Model' is not defined"
     ]
    }
   ],
   "source": [
    "model = Generate_Model(\"cifar10\", \"vgg16_bn\")\n",
    "model = load_resume_model(model, \"cifar10\", \"vgg16_bn\")\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "save_path = \"./adv_samples/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:33<00:00,  4.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[fgsm]ASR:100.0(10000/10000)\n",
      "[LinfFastGradientAttack(rel_stepsize=1.0, abs_stepsize=None, steps=1, random_start=False),cifar10]Save samples and labels successfully!\n"
     ]
    }
   ],
   "source": [
    "generate_adv_version2(dataloader, ori_model, save_path, _attack=\"fgsm\", dataset=\"cifar10\", epsilon=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 2/157 [1:54:20<145:21:14, 3375.97s/it]"
     ]
    }
   ],
   "source": [
    "generate_adv_version2(dataloader, ori_model, save_path, _attack=\"cw\", dataset=\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [21:35<00:00,  8.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pgd]ASR:100.0(10000/10000)\n",
      "[LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True),cifar10]Save samples and labels successfully!\n"
     ]
    }
   ],
   "source": [
    "generate_adv_version2(dataloader, ori_model, save_path, _attack=\"pgd\", dataset=\"mnist\", epsilon=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_adv_version2(dataloader, ori_model, save_path, _attack=\"fgsm\", dataset=\"cifar10\", epsilon=0.004)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_adv_version2(dataloader, ori_model, save_path, _attack=\"fgsm\", dataset=\"cifar10\", epsilon=0.012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_adv_version2(dataloader, ori_model, save_path, _attack=\"fgsm\", dataset=\"cifar10\", epsilon=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:24<00:00,  2.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pgd]ASR:92.56(24094/26032)\n",
      "[LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True),SVHN]Save samples and labels successfully!\n"
     ]
    }
   ],
   "source": [
    "transform_test = T.Compose([\n",
    "                T.ToTensor(),\n",
    "    #             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "train_data = torchvision.datasets.SVHN(\n",
    "        root = '../data/SVHN',\n",
    "        split = 'train',\n",
    "        transform = transform_test,\n",
    "        download = False\n",
    ")\n",
    "test_data = torchvision.datasets.SVHN(\n",
    "        root = '../data/SVHN',\n",
    "        split = 'test',\n",
    "        transform = transform_test,\n",
    "        download = False\n",
    ")\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=640, shuffle=False)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=640, shuffle=False)\n",
    "\n",
    "model = AlexNet(num_classes=10)\n",
    "model_path = \"../trained_models/alexnet_lr0.0001_39.pkl\"\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "generate_adv_version2(test_loader, model, \"\", _attack=\"pgd\", dataset=\"SVHN\", epsilon=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:13<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pgd]ASR:49.83(12971/26032)\n",
      "[LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True),SVHN]Save samples and labels successfully!\n"
     ]
    }
   ],
   "source": [
    "transform_test = T.Compose([\n",
    "                T.ToTensor(),\n",
    "    #             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "train_data = torchvision.datasets.SVHN(\n",
    "        root = '../data/SVHN',\n",
    "        split = 'train',\n",
    "        transform = transform_test,\n",
    "        download = False\n",
    ")\n",
    "test_data = torchvision.datasets.SVHN(\n",
    "        root = '../data/SVHN',\n",
    "        split = 'test',\n",
    "        transform = transform_test,\n",
    "        download = False\n",
    ")\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=640, shuffle=False)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=640, shuffle=False)\n",
    "\n",
    "model = AlexNet(num_classes=10)\n",
    "model_path = \"../trained_models/PAT/PAT_epoch59_lr0.001.pkl\"\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "generate_adv_version2(test_loader, model, \"\", _attack=\"pgd\", dataset=\"SVHN\", epsilon=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:27<00:00,  2.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pgd]ASR:47.04(12246/26032)\n",
      "[LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True),SVHN]Save samples and labels successfully!\n"
     ]
    }
   ],
   "source": [
    "transform_test = T.Compose([\n",
    "                T.ToTensor(),\n",
    "    #             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "train_data = torchvision.datasets.SVHN(\n",
    "        root = '../data/SVHN',\n",
    "        split = 'train',\n",
    "        transform = transform_test,\n",
    "        download = False\n",
    ")\n",
    "test_data = torchvision.datasets.SVHN(\n",
    "        root = '../data/SVHN',\n",
    "        split = 'test',\n",
    "        transform = transform_test,\n",
    "        download = False\n",
    ")\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=640, shuffle=False)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=640, shuffle=False)\n",
    "\n",
    "model = AlexNet(num_classes=10)\n",
    "model_path = \"../trained_models/PAT/PAT_epoch59_lr0.0001.pkl\"\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "generate_adv_version2(test_loader, model, \"\", _attack=\"pgd\", dataset=\"SVHN\", epsilon=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 41/41 [01:18<00:00,  1.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pgd]ASR:54.81(14267/26032)\n",
      "[LinfProjectedGradientDescentAttack(rel_stepsize=0.03333333333333333, abs_stepsize=None, steps=40, random_start=True),SVHN]Save samples and labels successfully!\n"
     ]
    }
   ],
   "source": [
    "transform_test = T.Compose([\n",
    "                T.ToTensor(),\n",
    "    #             transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "train_data = torchvision.datasets.SVHN(\n",
    "        root = '../data/SVHN',\n",
    "        split = 'train',\n",
    "        transform = transform_test,\n",
    "        download = False\n",
    ")\n",
    "test_data = torchvision.datasets.SVHN(\n",
    "        root = '../data/SVHN',\n",
    "        split = 'test',\n",
    "        transform = transform_test,\n",
    "        download = False\n",
    ")\n",
    "train_loader = Data.DataLoader(dataset=train_data, batch_size=640, shuffle=False)\n",
    "test_loader = Data.DataLoader(dataset=test_data, batch_size=640, shuffle=False)\n",
    "\n",
    "model = AlexNet(num_classes=10)\n",
    "model_path = \"../trained_models/PAT/PAT_epoch59_lr1e-05.pkl\"\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "\n",
    "generate_adv_version2(test_loader, model, \"\", _attack=\"pgd\", dataset=\"SVHN\", epsilon=0.03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
