{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import json\n",
    "import sys\n",
    "sys.path.append(\"models\")\n",
    "from VGG_16 import VGG16\n",
    "import os\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from collections import Counter\n",
    "import torchvision.datasets as datasets\n",
    "import random\n",
    "import torch.utils.data as Data\n",
    "import torch.nn.functional as F\n",
    "import argparse\n",
    "from resnet import *\n",
    "from model_mask_resnet import *\n",
    "from model_mask_vgg import mask_VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "[10, 5, 7]\n",
      "[0.15625, 0.078125, 0.0546875]\n",
      "[0.15625, 0.078125, 0.0546875]\n",
      "0.09635416666666667\n"
     ]
    }
   ],
   "source": [
    "feature_size = [64, 64, 128]\n",
    "data_path = \"LRP_path/mnist_convmnist_lrp_path_threshold0.7_train.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths_all = pickle.load(fr)\n",
    "    print(len(paths_all))\n",
    "    \n",
    "num_layers = len(paths_all[0])\n",
    "length = [0 for i in range(num_layers)]\n",
    "\n",
    "for p in range(len(paths_all)):\n",
    "    for i in range(num_layers):\n",
    "        length[i] += len(paths_all[p][i])\n",
    "for i in range(num_layers):\n",
    "    length[i] = round(length[i]/len(paths_all))\n",
    "print(length)\n",
    "\n",
    "por = []\n",
    "for i in range(num_layers):\n",
    "    por.append(length[i]/feature_size[i])\n",
    "print(por)\n",
    "\n",
    "\n",
    "a = por\n",
    "print(a)\n",
    "value = 0\n",
    "for v in a:\n",
    "    value += v\n",
    "print(value/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "[6, 9, 18, 14, 11, 16, 92, 26]\n",
      "[0.1875, 0.28125, 0.28125, 0.21875, 0.0859375, 0.125, 0.08984375, 0.05078125]\n",
      "[0.1875, 0.28125, 0.28125, 0.21875, 0.0859375, 0.125, 0.08984375, 0.05078125]\n",
      "0.1650390625\n"
     ]
    }
   ],
   "source": [
    "feature_size = [32, 32, 64, 64, 128, 128, 1024, 512]\n",
    "data_path = \"LRP_path/cifar10_convcifar10_lrp_path_threshold0.6_train.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths_all = pickle.load(fr)\n",
    "    print(len(paths_all))\n",
    "    \n",
    "num_layers = len(paths_all[0])\n",
    "length = [0 for i in range(num_layers)]\n",
    "\n",
    "for p in range(len(paths_all)):\n",
    "    for i in range(num_layers):\n",
    "        length[i] += len(paths_all[p][i])\n",
    "for i in range(num_layers):\n",
    "    length[i] = round(length[i]/len(paths_all))\n",
    "print(length)\n",
    "\n",
    "por = []\n",
    "for i in range(num_layers):\n",
    "    por.append(length[i]/feature_size[i])\n",
    "print(por)\n",
    "\n",
    "\n",
    "a = por\n",
    "print(a)\n",
    "value = 0\n",
    "for v in a:\n",
    "    value += v\n",
    "print(value/len(a))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n",
      "[9, 23, 32, 35, 23, 8, 8, 5, 3, 3, 3, 2, 60]\n",
      "[0.140625, 0.359375, 0.25, 0.2734375, 0.08984375, 0.03125, 0.03125, 0.009765625, 0.005859375, 0.005859375, 0.005859375, 0.00390625, 0.1171875]\n",
      "[0.140625, 0.359375, 0.25, 0.2734375, 0.08984375, 0.03125, 0.03125, 0.009765625, 0.005859375, 0.005859375, 0.005859375, 0.00390625, 0.1171875]\n",
      "0.10186298076923077\n"
     ]
    }
   ],
   "source": [
    "feature_size = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]\n",
    "data_path = \"LRP_path/cifar10_vgg_lrp_path_threshold0.7_train.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths_all = pickle.load(fr)\n",
    "    print(len(paths_all))\n",
    "    \n",
    "num_layers = len(paths_all[0])\n",
    "length = [0 for i in range(num_layers)]\n",
    "\n",
    "for p in range(len(paths_all)):\n",
    "    for i in range(num_layers):\n",
    "        length[i] += len(paths_all[p][i])\n",
    "for i in range(num_layers):\n",
    "    length[i] = round(length[i]/len(paths_all))\n",
    "print(length)\n",
    "\n",
    "por = []\n",
    "for i in range(num_layers):\n",
    "    por.append(length[i]/feature_size[i])\n",
    "print(por)\n",
    "\n",
    "a = por\n",
    "print(a)\n",
    "value = 0\n",
    "for v in a:\n",
    "    value += v\n",
    "print(value/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "data_path = \"LRP_path/imagenet10_vgg16_bn_lrp_path_threshold0.8_train_rest_15.pkl\"\n",
    "new_data_path = \"LRP_path/imagenet10_vgg16_bn_lrp_path_threshold0.8_train_rest.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths_all = pickle.load(fr)\n",
    "    print(len(paths_all))\n",
    "new_paths = {}\n",
    "for p in paths_all.keys():\n",
    "    new_paths[p] = (paths_all[p][:-2])\n",
    "#     print(len(new_paths[p]))\n",
    "output = open(new_data_path, 'wb')\n",
    "pickle.dump(new_paths, output)  \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000\n",
      "[38, 61, 104, 123, 247, 254, 255, 511, 501, 502, 492, 451, 348]\n",
      "[0.59375, 0.953125, 0.8125, 0.9609375, 0.96484375, 0.9921875, 0.99609375, 0.998046875, 0.978515625, 0.98046875, 0.9609375, 0.880859375, 0.6796875]\n",
      "[0.59375, 0.953125, 0.8125, 0.9609375, 0.96484375, 0.9921875, 0.99609375, 0.998046875, 0.978515625, 0.98046875, 0.9609375, 0.880859375, 0.6796875]\n",
      "0.9039963942307693\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "feature_size = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]\n",
    "data_path = \"LRP_path/imagenet_vgg16_bn_ft_lrp_path_threshold1.0_train.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths_all = pickle.load(fr)\n",
    "    print(len(paths_all))\n",
    "    \n",
    "num_layers = len(paths_all[0])\n",
    "length = [0 for i in range(num_layers)]\n",
    "\n",
    "for p in range(len(paths_all)):\n",
    "    for i in range(num_layers):\n",
    "        length[i] += len(paths_all[p][i])\n",
    "for i in range(num_layers):\n",
    "    length[i] = round(length[i]/len(paths_all))\n",
    "print(length)\n",
    "\n",
    "por = []\n",
    "for i in range(num_layers):\n",
    "    por.append(length[i]/feature_size[i])\n",
    "print(por)\n",
    "\n",
    "a = por\n",
    "print(a)\n",
    "value = 0\n",
    "for v in a:\n",
    "    value += v\n",
    "print(value/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13000\n",
      "[64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 511, 499, 449]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.974609375, 0.876953125]\n",
      "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.998046875, 0.974609375, 0.876953125]\n",
      "0.9884314903846154\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "feature_size = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]\n",
    "data_path = \"LRP_path/imagenet_vgg16_bn_lrp_path_threshold1.0_train.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths_all = pickle.load(fr)\n",
    "    print(len(paths_all))\n",
    "    \n",
    "num_layers = len(paths_all[0])\n",
    "length = [0 for i in range(num_layers)]\n",
    "\n",
    "for p in range(len(paths_all)):\n",
    "    for i in range(num_layers):\n",
    "        length[i] += len(paths_all[p][i])\n",
    "for i in range(num_layers):\n",
    "    length[i] = round(length[i]/len(paths_all))\n",
    "print(length)\n",
    "\n",
    "por = []\n",
    "for i in range(num_layers):\n",
    "    por.append(length[i]/feature_size[i])\n",
    "print(por)\n",
    "\n",
    "a = por\n",
    "print(a)\n",
    "value = 0\n",
    "for v in a:\n",
    "    value += v\n",
    "print(value/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73257\n",
      "[57, 151, 219, 121, 131]\n",
      "[0.890625, 0.7864583333333334, 0.5703125, 0.47265625, 0.51171875]\n",
      "[0.890625, 0.7864583333333334, 0.5703125, 0.47265625, 0.51171875]\n",
      "0.6463541666666667\n"
     ]
    }
   ],
   "source": [
    "feature_size = [64, 192, 384, 256, 256]\n",
    "data_path = \"LRP_path/SVHN_alexnet_lrp_path_threshold1.0_train.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths_all = pickle.load(fr)\n",
    "    print(len(paths_all))\n",
    "    \n",
    "num_layers = len(paths_all[0])\n",
    "length = [0 for i in range(num_layers)]\n",
    "\n",
    "for p in range(len(paths_all)):\n",
    "    for i in range(num_layers):\n",
    "        length[i] += len(paths_all[p][i])\n",
    "for i in range(num_layers):\n",
    "    length[i] = round(length[i]/len(paths_all))\n",
    "print(length)\n",
    "\n",
    "por = []\n",
    "for i in range(num_layers):\n",
    "    por.append(length[i]/feature_size[i])\n",
    "print(por)\n",
    "\n",
    "a = por\n",
    "print(a)\n",
    "value = 0\n",
    "for v in a:\n",
    "    value += v\n",
    "print(value/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ab53dd26643b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mpor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mpor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfeature_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m#     print(por)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "num_clusters = [1,4,7,10]\n",
    "thresholds = [0.6,0.7,0.8,0.9]\n",
    "for num_cluster in num_clusters:\n",
    "    for threshold in thresholds:\n",
    "    # num_cluster = 4\n",
    "    # threshold = 0.8\n",
    "        feature_size = [64, 64, 128]\n",
    "        for cla in range(10):\n",
    "            for clu in range(num_cluster):\n",
    "        #         l = \"{}_{}\".format(cla, clu)\n",
    "                picked_samples_fname = \"cluster_paths/convmnist_binary_cluster/num_cluster{}_threshold{}_class{}_cluster{}_paths.pkl\".format(num_cluster, threshold, cla, clu)\n",
    "                with open(picked_samples_fname, \"rb\") as f:\n",
    "                    unpickler = pickle.Unpickler(f)\n",
    "                    path = unpickler.load()\n",
    "                    path = path[0]\n",
    "                if cla == 0 and clu == 0:\n",
    "                    num_layers = len(path)\n",
    "                    length = [0 for i in range(len(path))]\n",
    "    #                 print(num_layers)\n",
    "\n",
    "                for i in range(num_layers):\n",
    "                    length[i] += len(path[i])\n",
    "        for i in range(num_layers):\n",
    "            length[i] = round(length[i]/(num_cluster*10))\n",
    "#         print(length)\n",
    "\n",
    "        por = []\n",
    "        for i in range(num_layers):\n",
    "            por.append(length[i]/feature_size[i])\n",
    "    #     print(por)\n",
    "\n",
    "        a = por\n",
    "    #     print(a)\n",
    "        value = 0\n",
    "        for v in a:\n",
    "            value += v\n",
    "        print(\"{}_{}: {}\".format(num_cluster, threshold, value/len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_0.6: 0.13916015625\n",
      "1_0.7: 0.0946044921875\n",
      "1_0.8: 0.0640869140625\n",
      "1_0.9: 0.0635986328125\n",
      "4_0.6: 0.1461181640625\n",
      "4_0.7: 0.108642578125\n",
      "4_0.8: 0.0765380859375\n",
      "4_0.9: 0.0718994140625\n",
      "7_0.6: 0.1485595703125\n",
      "7_0.7: 0.1121826171875\n",
      "7_0.8: 0.079345703125\n",
      "7_0.9: 0.0814208984375\n",
      "10_0.6: 0.151611328125\n",
      "10_0.7: 0.1153564453125\n",
      "10_0.8: 0.082763671875\n",
      "10_0.9: 0.0543212890625\n"
     ]
    }
   ],
   "source": [
    "# num_cluster = 10\n",
    "# threshold = 0.8\n",
    "num_clusters = [1, 4, 7, 10]\n",
    "thresholds = [0.6, 0.7, 0.8, 0.9]\n",
    "for num_cluster in num_clusters:\n",
    "    for threshold in thresholds:\n",
    "        feature_size = [32, 32, 64, 64, 128, 128, 1024, 512]\n",
    "        for cla in range(10):\n",
    "            for clu in range(num_cluster):\n",
    "        #         l = \"{}_{}\".format(cla, clu)\n",
    "                picked_samples_fname = \"cluster_paths/convcifar10_binary_cluster/num_cluster{}_threshold{}_class{}_cluster{}_paths.pkl\".format(num_cluster, threshold, cla, clu)\n",
    "                with open(picked_samples_fname, \"rb\") as f:\n",
    "                    unpickler = pickle.Unpickler(f)\n",
    "                    path = unpickler.load()\n",
    "                    path = path[0]\n",
    "                if cla == 0 and clu == 0:\n",
    "                    num_layers = len(path)\n",
    "                    length = [0 for i in range(len(path))]\n",
    "    #                 print(num_layers)\n",
    "\n",
    "                for i in range(num_layers):\n",
    "                    length[i] += len(path[i])\n",
    "        for i in range(num_layers):\n",
    "            length[i] = round(length[i]/(num_cluster*10))\n",
    "    #     print(length)\n",
    "\n",
    "        por = []\n",
    "        for i in range(num_layers):\n",
    "            por.append(length[i]/feature_size[i])\n",
    "    #     print(por)\n",
    "\n",
    "        a = por\n",
    "    #     print(a)\n",
    "        value = 0\n",
    "        for v in a:\n",
    "            value += v\n",
    "        print(\"{}_{}: {}\".format(num_cluster, threshold, value/len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1_0.6: 0.4151141826923077\n",
      "1_0.7: 0.34390024038461536\n",
      "1_0.8: 0.263671875\n",
      "1_0.9: 0.17698317307692307\n",
      "4_0.6: 0.5456730769230769\n",
      "4_0.7: 0.49008413461538464\n",
      "4_0.8: 0.40444711538461536\n",
      "4_0.9: 0.34314903846153844\n",
      "7_0.6: 0.6428786057692307\n",
      "7_0.7: 0.5949519230769231\n",
      "7_0.8: 0.5181790865384616\n",
      "7_0.9: 0.46664663461538464\n",
      "10_0.6: 0.732421875\n",
      "10_0.7: 0.7047776442307693\n",
      "10_0.8: 0.5835336538461539\n",
      "10_0.9: 0.5432692307692307\n"
     ]
    }
   ],
   "source": [
    "# num_cluster = 3\n",
    "# threshold = 0.85\n",
    "num_clusters = [1,4,7,10]\n",
    "thresholds = [0.6,0.7,0.8,0.9]\n",
    "for num_cluster in num_clusters:\n",
    "    for threshold in thresholds:\n",
    "        feature_size = [64, 64, 128, 128, 256, 256, 256, 512, 512, 512, 512, 512, 512]\n",
    "        for cla in range(10):\n",
    "            for clu in range(num_cluster):\n",
    "        #         l = \"{}_{}\".format(cla, clu)\n",
    "                picked_samples_fname = \"cluster_paths/vgg16_bn_binary_cluster/num_cluster{}_threshold{}_class{}_cluster{}_paths.pkl\".format(num_cluster, threshold, cla, clu)\n",
    "                with open(picked_samples_fname, \"rb\") as f:\n",
    "                    unpickler = pickle.Unpickler(f)\n",
    "                    path = unpickler.load()\n",
    "                    path = path[0]\n",
    "                if cla == 0 and clu == 0:\n",
    "                    num_layers = len(path)\n",
    "                    length = [0 for i in range(len(path))]\n",
    "#                     print(num_layers)\n",
    "\n",
    "                for i in range(num_layers):\n",
    "                    length[i] += len(path[i])\n",
    "        for i in range(num_layers):\n",
    "            length[i] = round(length[i]/(num_cluster*10))\n",
    "#         print(length)\n",
    "\n",
    "        por = []\n",
    "        for i in range(num_layers):\n",
    "            por.append(length[i]/feature_size[i])\n",
    "        a = por\n",
    "#         print(a)\n",
    "        value = 0\n",
    "        for v in a:\n",
    "            value += v\n",
    "        print(\"{}_{}: {}\".format(num_cluster, threshold, value/len(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### num_clusters = [1, 4, 7, 10]\n",
    "thresholds = [0.7]\n",
    "for num_cluster in num_clusters:\n",
    "    for threshold in thresholds:\n",
    "    # num_cluster = 4\n",
    "    # threshold = 0.8\n",
    "        feature_size = [64, 192, 384, 256, 256]\n",
    "        for cla in range(10):\n",
    "            for clu in range(num_cluster):\n",
    "        #         l = \"{}_{}\".format(cla, clu)\n",
    "                picked_samples_fname = \"cluster_paths/alexnet_binary_cluster/num_cluster{}_threshold{}_class{}_cluster{}_paths.pkl\".format(num_cluster, threshold, cla, clu)\n",
    "                with open(picked_samples_fname, \"rb\") as f:\n",
    "                    unpickler = pickle.Unpickler(f)\n",
    "                    path = unpickler.load()\n",
    "                    path = path[0]\n",
    "                if cla == 0 and clu == 0:\n",
    "                    num_layers = len(path)\n",
    "                    length = [0 for i in range(len(path))]\n",
    "    #                 print(num_layers)\n",
    "\n",
    "                for i in range(num_layers):\n",
    "                    length[i] += len(path[i])\n",
    "        for i in range(num_layers):\n",
    "            length[i] = round(length[i]/(num_cluster*10))\n",
    "#         print(length)\n",
    "\n",
    "        por = []\n",
    "        for i in range(num_layers):\n",
    "            por.append(length[i]/feature_size[i])\n",
    "    #     print(por)\n",
    "\n",
    "        a = por\n",
    "    #     print(a)\n",
    "        value = 0\n",
    "        for v in a:\n",
    "            value += v\n",
    "        print(\"{}_{}: {}\".format(num_cluster, threshold, value/len(a)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a = set([1, 2])\n",
    "b = set([1, 3])\n",
    "a + b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
