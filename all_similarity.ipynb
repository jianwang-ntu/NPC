{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import torch\n",
    "from time import time\n",
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "import os\n",
    "import torchvision.transforms as T\n",
    "from collections import Counter\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import random\n",
    "import torch.utils.data as Data\n",
    "import gc\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def sim_layer(unitsA, unitsB):\n",
    "    u = list(set(unitsA) | set(unitsB))\n",
    "    i = list(set(unitsA) & set(unitsB))\n",
    "    return len(i)/len(u)\n",
    "\n",
    "def similarity(pathsA, pathsB):\n",
    "    sim = 0\n",
    "    sims = []\n",
    "    for layer in range(len(pathsA)):\n",
    "        sim += sim_layer(pathsA[layer], pathsB[layer])\n",
    "        sims.append(sim_layer(pathsA[layer], pathsB[layer]))\n",
    "    sim = sim/len(pathsA)\n",
    "    return sim, sims\n",
    "\n",
    "def get_random(samples, num_picked, badboys=[]):\n",
    "    picked = []\n",
    "    indexs = []\n",
    "#     print(len(samples))\n",
    "    while len(picked) < num_picked:\n",
    "        index = random.randint(0, len(samples)-1)\n",
    "        if index not in indexs and index not in badboys:\n",
    "            indexs.append(index)\n",
    "            picked.append(samples[index])\n",
    "    return picked\n",
    "\n",
    "def get_similarity(samples1, samples2):\n",
    "    s_all = 0\n",
    "    sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "    for s1 in samples1:\n",
    "        p1 = paths[s1]\n",
    "        for s2 in samples2:\n",
    "            p2 = paths[s2]\n",
    "            s, sims = similarity(p1, p2)\n",
    "#             print(sims)\n",
    "            s_all += s\n",
    "            sims_avg = sims_avg + np.array(sims)       \n",
    "    s_avg = s_all / (len(samples1) * len(samples2))\n",
    "    return s_avg, sims_avg/(len(samples1) * len(samples2))\n",
    "\n",
    "def get_similarity_samples_cluster(samples1, path2):\n",
    "    s_all = 0\n",
    "    num = 0\n",
    "    sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "    for s1 in samples1:\n",
    "        p1 = paths[s1]\n",
    "        p2 = path2\n",
    "        s, sims = similarity(p1, p2)\n",
    "#             print(sims)\n",
    "        s_all += s\n",
    "        num += 1\n",
    "        sims_avg = sims_avg + np.array(sims)       \n",
    "    s_avg = s_all / num\n",
    "    return s_avg, sims_avg/num\n",
    "\n",
    "data_path = \"LRP_path/imagenet_vgg16_bn_lrp_path_threshold0.7_train.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths = pickle.load(fr)\n",
    "    \n",
    "picked_samples_classes = [[] for _ in range(10)]\n",
    "num_cluster = 4\n",
    "for cla in range(10):\n",
    "    for clu in range(num_cluster):\n",
    "        l = \"{}_{}\".format(cla, clu)\n",
    "        picked_samples_fname = \"cluster_paths/vgg16_bn_binary_cluster/num_cluster{}_class{}_cluster{}_picked_samples.pkl\".format(num_cluster, cla, clu)\n",
    "        with open(picked_samples_fname, \"rb\") as f:\n",
    "            unpickler = pickle.Unpickler(f)\n",
    "            picked_samples = unpickler.load()\n",
    "        picked_samples_classes[cla].append(picked_samples)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# samples_path with cluster_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "7\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3322bba7e512>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mpath2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_similarity_samples_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0ms_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"{}_{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcla\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0ms_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-acf80fd8a84c>\u001b[0m in \u001b[0;36mget_similarity_samples_cluster\u001b[0;34m(samples1, path2)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ms1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m         \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;31m#             print(sims)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0ms_all\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-acf80fd8a84c>\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(pathsA, pathsB)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathsA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m         \u001b[0msim\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msim_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathsA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathsB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m         \u001b[0msims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathsA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpathsB\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0msim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpathsA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "picked_num = 5\n",
    "sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "s_all = 0\n",
    "num = 0\n",
    "s_dict = {}\n",
    "for cla in range(10):\n",
    "    for clu in range(num_cluster):\n",
    "        samples1 = get_random(picked_samples_classes[cla][clu], picked_num, [])\n",
    "        samples2 = get_random(picked_samples_classes[cla][clu], picked_num, samples1)\n",
    "        path_fname = \"cluster_paths/convmnist_binary_cluster/num_cluster{}_threshold{}_class{}_cluster{}_paths.pkl\".format(num_cluster, 0.4, cla, clu)\n",
    "        with open(path_fname, \"rb\") as f:\n",
    "            unpickler = pickle.Unpickler(f)\n",
    "            path2 = unpickler.load()[0]\n",
    "        s, sims = get_similarity_samples_cluster(samples1, path2)\n",
    "        s_dict[\"{}_{}\".format(cla, clu)] = s\n",
    "        s_all += s\n",
    "        sims_avg = sims_avg + sims \n",
    "        num += 1\n",
    "print(s_all/num)\n",
    "print(sims_avg/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6334631036457855\n",
      "[0.6839908  0.76361491 0.4527836 ]\n"
     ]
    }
   ],
   "source": [
    "# picked_num = 100\n",
    "# sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "# s_all = 0\n",
    "# num = 0\n",
    "# for cla in range(10):\n",
    "#     for clu in range(num_cluster):\n",
    "#         for clu2 in range(num_cluster):\n",
    "#             if clu != clu2:\n",
    "#                 samples1 = get_random(picked_samples_classes[cla][clu2], picked_num, [])\n",
    "#                 path_fname = \"cluster_paths/convmnist_binary_cluster/num_cluster{}_threshold{}_class{}_cluster{}_paths.pkl\".format(num_cluster, 0.4, cla, clu)\n",
    "#                 with open(path_fname, \"rb\") as f:\n",
    "#                     unpickler = pickle.Unpickler(f)\n",
    "#                     path2 = unpickler.load()[0]\n",
    "#                 s, sims = get_similarity_samples_cluster(samples1, path2)\n",
    "#         #         print(s)\n",
    "#                 s_all += s\n",
    "#                 sims_avg = sims_avg + sims \n",
    "#                 num += 1\n",
    "# print(s_all/num)\n",
    "# print(sims_avg/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# picked_num = 100\n",
    "# sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "# s_all = 0\n",
    "# num = 0\n",
    "# for cla in range(10):\n",
    "#     for clu in range(num_cluster):\n",
    "#         for clu2 in range(num_cluster):\n",
    "#             if clu != clu2:\n",
    "#                 path_fname = \"cluster_paths/convmnist_binary_cluster/num_cluster{}_threshold{}_class{}_cluster{}_paths.pkl\".format(num_cluster, 0.4, cla, clu2)\n",
    "#                 path_fname = \"cluster_paths/convmnist_binary_cluster/num_cluster{}_threshold{}_class{}_cluster{}_paths.pkl\".format(num_cluster, 0.4, cla, clu)\n",
    "#                 with open(path_fname, \"rb\") as f:\n",
    "#                     unpickler = pickle.Unpickler(f)\n",
    "#                     path2 = unpickler.load()[0]\n",
    "#                 s, sims = get_similarity_samples_cluster(samples1, path2)\n",
    "#         #         print(s)\n",
    "#                 s_all += s\n",
    "#                 sims_avg = sims_avg + sims \n",
    "#                 num += 1\n",
    "# print(s_all/num)\n",
    "# print(sims_avg/num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6584000462138969\n",
      "[0.70624392 0.77821609 0.49074013]\n"
     ]
    }
   ],
   "source": [
    "# picked_num = 10\n",
    "# sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "# s_all = 0\n",
    "# num = 0\n",
    "# for cla in range(10):\n",
    "#     for cla2 in range(10):\n",
    "#         if cla != cla2:\n",
    "#             for clu in range(num_cluster):\n",
    "#                 for clu2 in range(num_cluster):\n",
    "                \n",
    "#                     samples1 = get_random(picked_samples_classes[cla][clu2], picked_num, [])\n",
    "#                     path_fname = \"cluster_paths/convmnist_binary_cluster/num_cluster{}_threshold{}_class{}_cluster{}_paths.pkl\".format(num_cluster, 0.4, cla, clu)\n",
    "#                     with open(path_fname, \"rb\") as f:\n",
    "#                         unpickler = pickle.Unpickler(f)\n",
    "#                         path2 = unpickler.load()[0]\n",
    "#                     s, sims = get_similarity_samples_cluster(samples1, path2)\n",
    "#             #         print(s)\n",
    "#                     s_all += s\n",
    "#                     sims_avg = sims_avg + sims \n",
    "#                     num += 1\n",
    "# print(s_all/num)\n",
    "# print(sims_avg/num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity of inter-cluster of different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cla1, cla2 0 0\n",
      "cla1, cla2 0 1\n",
      "cla1, cla2 0 2\n",
      "cla1, cla2 0 3\n",
      "cla1, cla2 0 4\n",
      "cla1, cla2 0 5\n",
      "cla1, cla2 0 6\n",
      "cla1, cla2 0 7\n",
      "cla1, cla2 0 8\n",
      "cla1, cla2 0 9\n",
      "cla1, cla2 1 0\n",
      "cla1, cla2 1 1\n",
      "cla1, cla2 1 2\n",
      "cla1, cla2 1 3\n",
      "cla1, cla2 1 4\n",
      "cla1, cla2 1 5\n",
      "cla1, cla2 1 6\n",
      "cla1, cla2 1 7\n",
      "cla1, cla2 1 8\n",
      "cla1, cla2 1 9\n",
      "cla1, cla2 2 0\n",
      "cla1, cla2 2 1\n",
      "cla1, cla2 2 2\n",
      "cla1, cla2 2 3\n",
      "cla1, cla2 2 4\n",
      "cla1, cla2 2 5\n",
      "cla1, cla2 2 6\n",
      "cla1, cla2 2 7\n",
      "cla1, cla2 2 8\n",
      "cla1, cla2 2 9\n",
      "cla1, cla2 3 0\n",
      "cla1, cla2 3 1\n",
      "cla1, cla2 3 2\n",
      "cla1, cla2 3 3\n",
      "cla1, cla2 3 4\n",
      "cla1, cla2 3 5\n",
      "cla1, cla2 3 6\n",
      "cla1, cla2 3 7\n",
      "cla1, cla2 3 8\n",
      "cla1, cla2 3 9\n",
      "cla1, cla2 4 0\n",
      "cla1, cla2 4 1\n",
      "cla1, cla2 4 2\n",
      "cla1, cla2 4 3\n",
      "cla1, cla2 4 4\n",
      "cla1, cla2 4 5\n",
      "cla1, cla2 4 6\n",
      "cla1, cla2 4 7\n",
      "cla1, cla2 4 8\n",
      "cla1, cla2 4 9\n",
      "cla1, cla2 5 0\n",
      "cla1, cla2 5 1\n",
      "cla1, cla2 5 2\n",
      "cla1, cla2 5 3\n",
      "cla1, cla2 5 4\n",
      "cla1, cla2 5 5\n",
      "cla1, cla2 5 6\n",
      "cla1, cla2 5 7\n",
      "cla1, cla2 5 8\n",
      "cla1, cla2 5 9\n",
      "cla1, cla2 6 0\n",
      "cla1, cla2 6 1\n",
      "cla1, cla2 6 2\n",
      "cla1, cla2 6 3\n",
      "cla1, cla2 6 4\n",
      "cla1, cla2 6 5\n",
      "cla1, cla2 6 6\n",
      "cla1, cla2 6 7\n",
      "cla1, cla2 6 8\n",
      "cla1, cla2 6 9\n",
      "cla1, cla2 7 0\n",
      "cla1, cla2 7 1\n",
      "cla1, cla2 7 2\n",
      "cla1, cla2 7 3\n",
      "cla1, cla2 7 4\n",
      "cla1, cla2 7 5\n",
      "cla1, cla2 7 6\n",
      "cla1, cla2 7 7\n",
      "cla1, cla2 7 8\n",
      "cla1, cla2 7 9\n",
      "cla1, cla2 8 0\n",
      "cla1, cla2 8 1\n",
      "cla1, cla2 8 2\n",
      "cla1, cla2 8 3\n",
      "cla1, cla2 8 4\n",
      "cla1, cla2 8 5\n",
      "cla1, cla2 8 6\n",
      "cla1, cla2 8 7\n",
      "cla1, cla2 8 8\n",
      "cla1, cla2 8 9\n",
      "cla1, cla2 9 0\n",
      "cla1, cla2 9 1\n",
      "cla1, cla2 9 2\n",
      "cla1, cla2 9 3\n",
      "cla1, cla2 9 4\n",
      "cla1, cla2 9 5\n",
      "cla1, cla2 9 6\n",
      "cla1, cla2 9 7\n",
      "cla1, cla2 9 8\n",
      "cla1, cla2 9 9\n",
      "0.3190640873241571\n",
      "[0.33272164 0.35439622 0.35340014 0.38399587 0.35219808 0.36592505\n",
      " 0.39169072 0.35068034 0.34508539 0.33464161 0.24541412 0.2014933\n",
      " 0.13619066]\n",
      "max 0.5611256624969195\n",
      "min 0.12600594446348776\n",
      "mean 0.3190640873241569\n"
     ]
    }
   ],
   "source": [
    "picked_num = 10\n",
    "sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "s_all = 0\n",
    "s_array = []\n",
    "num = 0\n",
    "for cla in range(10):\n",
    "    for cla2 in range(10):\n",
    "#         print(\"cla1, cla2\", cla, cla2)\n",
    "        if cla != cla2:\n",
    "            for clu in range(num_cluster):\n",
    "                for clu2 in range(num_cluster): \n",
    "                    if len(picked_samples_classes[cla][clu]) < picked_num or len(picked_samples_classes[cla2][clu2]) < picked_num:\n",
    "                        break\n",
    "                    samples1 = get_random(picked_samples_classes[cla][clu], picked_num, [])\n",
    "                    samples2 = get_random(picked_samples_classes[cla2][clu2], picked_num, [])\n",
    "                    s, sims = get_similarity(samples1, samples2)\n",
    "                    s_all += s\n",
    "                    s_array.append(s)\n",
    "                    sims_avg = sims_avg + sims \n",
    "                    num += 1\n",
    "print(s_all/num)\n",
    "print(sims_avg/num)\n",
    "print(\"max\", max(s_array))\n",
    "print(\"min\", min(s_array))\n",
    "print(\"mean\", np.mean(s_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity of intra-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5459249085999283\n",
      "[0.53437095 0.53865626 0.52708599 0.55141106 0.52784171 0.53334347\n",
      " 0.55591333 0.53295616 0.54729817 0.56769121 0.54404282 0.56432654\n",
      " 0.57208617]\n",
      "{'0_0': 0.6056873324929635, '0_1': 0.6130801558054002, '0_2': 0.6617865410564999, '0_3': 0.5250708970970669, '1_0': 0.6027246068810768, '1_1': 0.6970793196373224, '1_2': 0.5061038664171295, '1_3': 0.6592352907838332, '2_0': 0.5225304399537738, '2_1': 0.5212114502646282, '2_2': 0.510060592551235, '2_3': 0.5783574020821443, '3_0': 0.5207383091731629, '3_1': 0.517130036993969, '3_2': 0.48005807874107737, '3_3': 0.5516010591514484, '4_0': 0.465737059396347, '4_1': 0.5156631090511905, '4_2': 0.5207439338775574, '4_3': 0.44094456109922364, '5_0': 0.43121185720156424, '5_1': 0.4641086450297034, '5_2': 0.4702674816162215, '5_3': 0.4386412630097257, '6_0': 0.4365751233749464, '6_1': 0.490163980638621, '6_2': 0.5326766184735288, '6_3': 0.5039377159792987, '7_0': 0.6158631708960008, '7_1': 0.6160206584121555, '7_2': 0.5626823192909356, '7_3': 0.6386746096871634, '8_0': 0.5807875860800207, '8_1': 0.6053520276995105, '8_2': 0.5742727553531547, '8_3': 0.5778671310419272, '9_0': 0.5928163206172927, '9_1': 0.5164589049172225, '9_2': 0.5913966008510344, '9_3': 0.5816775313200552}\n"
     ]
    }
   ],
   "source": [
    "picked_num = 20\n",
    "sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "s_all = 0\n",
    "num = 0\n",
    "s_dict = {}\n",
    "for cla in range(10):\n",
    "    for clu in range(num_cluster):\n",
    "        if len(picked_samples_classes[cla][clu]) < picked_num or len(picked_samples_classes[cla2][clu2]) < picked_num:\n",
    "            break\n",
    "        samples1 = get_random(picked_samples_classes[cla][clu], picked_num, [])\n",
    "        samples2 = get_random(picked_samples_classes[cla][clu], picked_num, samples1)\n",
    "        s, sims = get_similarity(samples1, samples2)\n",
    "        s_dict[\"{}_{}\".format(cla, clu)] = s\n",
    "        s_all += s\n",
    "        sims_avg = sims_avg + sims \n",
    "        num += 1\n",
    "print(s_all/num)\n",
    "print(sims_avg/num)\n",
    "print(s_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5465098825843722\n",
      "[0.53436335 0.53916049 0.52914786 0.55445695 0.53068046 0.53463495\n",
      " 0.55710649 0.53164919 0.54519196 0.5653617  0.5434667  0.56396414\n",
      " 0.57544423]\n",
      "{'0_0': 0.6121273392968356, '0_1': 0.6251347342603599, '0_2': 0.670103312166017, '0_3': 0.5285846212284557, '1_0': 0.5877626484248325, '1_1': 0.7193423950565897, '1_2': 0.5148953848845695, '1_3': 0.6288467402527598, '2_0': 0.5392567741035884, '2_1': 0.5419363057287281, '2_2': 0.5006832718622948, '2_3': 0.5557763484176094, '3_0': 0.5109393277515337, '3_1': 0.5048638913685174, '3_2': 0.4745915145251171, '3_3': 0.553485217408151, '4_0': 0.4708147523919613, '4_1': 0.5133039307707645, '4_2': 0.5230329371401319, '4_3': 0.456799940814739, '5_0': 0.45670670618408893, '5_1': 0.4664609401831165, '5_2': 0.47007574149212045, '5_3': 0.43203382970671356, '6_0': 0.4378045046075452, '6_1': 0.46751973710538336, '6_2': 0.5392944544762047, '6_3': 0.517916547420161, '7_0': 0.6064531045316682, '7_1': 0.6259543578514797, '7_2': 0.5652365290998839, '7_3': 0.6145467654166972, '8_0': 0.5871909099163533, '8_1': 0.6129946321900812, '8_2': 0.5497861692786352, '8_3': 0.5857600757658951, '9_0': 0.578673257411015, '9_1': 0.5358455051568588, '9_2': 0.5781995344190889, '9_3': 0.599660613308341}\n"
     ]
    }
   ],
   "source": [
    "picked_num = 20\n",
    "sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "s_all = 0\n",
    "num = 0\n",
    "s_dict = {}\n",
    "for cla in range(10):\n",
    "    for clu in range(num_cluster):\n",
    "        samples1 = get_random(picked_samples_classes[cla][clu], picked_num, [])\n",
    "        samples2 = get_random(picked_samples_classes[cla][clu], picked_num, samples1)\n",
    "        s, sims = get_similarity(samples1, samples2)\n",
    "        s_dict[\"{}_{}\".format(cla, clu)] = s\n",
    "        s_all += s\n",
    "        sims_avg = sims_avg + sims \n",
    "        num += 1\n",
    "print(s_all/num)\n",
    "print(sims_avg/num)\n",
    "print(s_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# similarity of inter-cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33003026487146414\n",
      "[0.34083939 0.35922467 0.35969687 0.38728214 0.35535685 0.36771186\n",
      " 0.3974765  0.35725385 0.35175481 0.34657715 0.26439252 0.22968486\n",
      " 0.17314197]\n",
      "max 0.6196778714042624\n",
      "min 0.20573534745935823\n",
      "mean 0.3300302648714642\n"
     ]
    }
   ],
   "source": [
    "pick_num = 20\n",
    "sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "s_all = 0\n",
    "num = 0\n",
    "s_array = []\n",
    "for cla in range(10):\n",
    "    for clu in range(num_cluster):\n",
    "        for clu2 in range(num_cluster):\n",
    "            if clu != clu2:\n",
    "                samples1 = get_random(picked_samples_classes[cla][clu], picked_num, [])\n",
    "                samples2 = get_random(picked_samples_classes[clu][clu2], picked_num, [])\n",
    "                s, sims = get_similarity(samples1, samples2)\n",
    "                s_all += s\n",
    "                s_array.append(s)\n",
    "                sims_avg = sims_avg + sims \n",
    "                num += 1\n",
    "print(s_all/num)\n",
    "print(sims_avg/num)          \n",
    "print(\"max\", max(s_array))\n",
    "print(\"min\", min(s_array))\n",
    "print(\"mean\", np.mean(s_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draw more in paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0\n",
      "1_0\n",
      "2_0\n",
      "3_0\n",
      "4_0\n",
      "5_0\n",
      "6_0\n",
      "7_0\n",
      "8_0\n",
      "9_0\n"
     ]
    }
   ],
   "source": [
    "data_path = \"LRP_path/mnist_convmnist_lrp_path_threshold0.8_train.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths = pickle.load(fr)\n",
    "\n",
    "picked_num = 50\n",
    "\n",
    "picked_samples_classes = [[] for _ in range(10)]\n",
    "num_cluster = 1\n",
    "clu = 0\n",
    "for cla in range(10):\n",
    "    for clu in range(num_cluster):\n",
    "        l = \"{}_{}\".format(cla, clu)\n",
    "        print(l)\n",
    "        picked_samples_fname = \"cluster_paths/convmnist_binary_cluster/num_cluster{}_class{}_cluster{}_picked_samples.pkl\".format(num_cluster, cla, clu)\n",
    "        with open(picked_samples_fname, \"rb\") as f:\n",
    "            unpickler = pickle.Unpickler(f)\n",
    "            picked_samples = unpickler.load()\n",
    "        picked_samples_classes[cla].append(picked_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0_0\n",
      "0_1\n",
      "0_2\n",
      "0_3\n",
      "0_4\n",
      "0_5\n",
      "0_6\n",
      "0_7\n",
      "0_8\n",
      "0_9\n",
      "[0.7, 0.4, 0.35, 0.28, 0.39, 0.29, 0.42, 0.39, 0.42, 0.34]\n",
      "1_1\n",
      "1_2\n",
      "1_3\n",
      "1_4\n",
      "1_5\n",
      "1_6\n",
      "1_7\n",
      "1_8\n",
      "1_9\n",
      "[0.59, 0.25, 0.19, 0.33, 0.2, 0.28, 0.31, 0.28, 0.27]\n",
      "2_2\n",
      "2_3\n",
      "2_4\n",
      "2_5\n",
      "2_6\n",
      "2_7\n",
      "2_8\n",
      "2_9\n",
      "[0.63, 0.49, 0.4, 0.46, 0.45, 0.41, 0.51, 0.5]\n",
      "3_3\n",
      "3_4\n",
      "3_5\n",
      "3_6\n",
      "3_7\n",
      "3_8\n",
      "3_9\n",
      "[0.68, 0.38, 0.56, 0.39, 0.38, 0.46, 0.49]\n",
      "4_4\n",
      "4_5\n",
      "4_6\n",
      "4_7\n",
      "4_8\n",
      "4_9\n",
      "[0.57, 0.36, 0.43, 0.43, 0.41, 0.44]\n",
      "5_5\n",
      "5_6\n",
      "5_7\n",
      "5_8\n",
      "5_9\n",
      "[0.63, 0.4, 0.37, 0.44, 0.47]\n",
      "6_6\n",
      "6_7\n",
      "6_8\n",
      "6_9\n",
      "[0.61, 0.39, 0.45, 0.42]\n",
      "7_7\n",
      "7_8\n",
      "7_9\n",
      "[0.56, 0.39, 0.46]\n",
      "8_8\n",
      "8_9\n",
      "[0.64, 0.47]\n",
      "9_9\n",
      "[0.64]\n",
      "0.39111111111111113\n",
      "0.625\n"
     ]
    }
   ],
   "source": [
    "sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "s_all = 0\n",
    "s_array = []\n",
    "num = 0\n",
    "results_simCla = []\n",
    "results_difCla = []\n",
    "for cla in range(10):\n",
    "    results = []\n",
    "    for cla2 in range(cla, 10):\n",
    "        print(\"{}_{}\".format(cla, cla2))\n",
    "        if cla == cla2:\n",
    "            samples1 = get_random(picked_samples_classes[cla][0], picked_num, [])\n",
    "            samples2 = get_random(picked_samples_classes[cla2][0], picked_num, samples1)\n",
    "        else:\n",
    "            samples1 = get_random(picked_samples_classes[cla][0], picked_num, [])\n",
    "            samples2 = get_random(picked_samples_classes[cla2][0], picked_num, [])\n",
    "        s, sims = get_similarity(samples1, samples2)\n",
    "        results.append(round(s, 2))\n",
    "        if cla2 == cla:\n",
    "            results_simCla.append(round(s, 2))\n",
    "        else:\n",
    "            results_difCla.append(round(s, 2))\n",
    "            \n",
    "    print(results)\n",
    "    \n",
    "print(np.mean(results_difCla))\n",
    "print(np.mean(results_simCla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9_0\n",
      "9_0\n",
      "9_0\n",
      "9_0\n",
      "9_0\n",
      "9_0\n",
      "9_0\n",
      "9_0\n",
      "9_0\n",
      "9_0\n"
     ]
    }
   ],
   "source": [
    "data_path = \"LRP_path/mnist_convmnist_lrp_path_threshold0.9_train.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths = pickle.load(fr)\n",
    "\n",
    "picked_num = 50\n",
    "\n",
    "picked_samples_classes = [[] for _ in range(10)]\n",
    "num_cluster = 1\n",
    "clu = 0\n",
    "for cla in range(10):\n",
    "    for clu in range(num_cluster):\n",
    "#         l = \"{}_{}\".format(cla, clu)\n",
    "#         print(l)\n",
    "        picked_samples_fname = \"cluster_paths/convmnist_binary_cluster/num_cluster{}_class{}_cluster{}_picked_samples.pkl\".format(num_cluster, cla, clu)\n",
    "        with open(picked_samples_fname, \"rb\") as f:\n",
    "            unpickler = pickle.Unpickler(f)\n",
    "            picked_samples = unpickler.load()\n",
    "        picked_samples_classes[cla].append(picked_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.63]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "nan\n",
      "0.63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xiaofei/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py:3257: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/home/xiaofei/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py:161: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "picked_num = 5\n",
    "sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "s_all = 0\n",
    "s_array = []\n",
    "num = 0\n",
    "results_simCla = []\n",
    "results_difCla = []\n",
    "for cla in range(10):\n",
    "    results = []\n",
    "    for cla2 in range(cla, 10):\n",
    "#         print(\"{}_{}\".format(cla, cla2))\n",
    "        p1 = []\n",
    "        for l in picked_samples_classes[cla]:\n",
    "            p1 = p1 + l\n",
    "        p2 = []\n",
    "        for l in picked_samples_classes[cla2]:\n",
    "            p2 = p2 + l\n",
    "#         p1 = [[].extend(l) for l in picked_samples_classes[cla]]\n",
    "#         p2 = [[].extend(l) for l in picked_samples_classes[cla2]]\n",
    "#         print(p1)\n",
    "        if cla == cla2:\n",
    "            if len(p1) < picked_num or len(p2) < picked_num:\n",
    "                break\n",
    "            samples1 = get_random(p1, picked_num, [])\n",
    "            samples2 = get_random(p2, picked_num, samples1)\n",
    "        else:\n",
    "            if len(p1) < picked_num or len(p2) < picked_num:\n",
    "                        break\n",
    "            samples1 = get_random(p1, picked_num, [])\n",
    "            samples2 = get_random(p2, picked_num, [])\n",
    "        s, sims = get_similarity(samples1, samples2)\n",
    "        results.append(round(s, 2))\n",
    "        if cla2 == cla:\n",
    "            results_simCla.append(round(s, 2))\n",
    "        else:\n",
    "            results_difCla.append(round(s, 2))\n",
    "            \n",
    "    print(results)\n",
    "    \n",
    "print(np.mean(results_difCla))\n",
    "print(np.mean(results_simCla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"LRP_path/mnist_convmnist_lrp_path_threshold1.0_train.pkl\"\n",
    "with open(data_path, 'rb') as fr:\n",
    "    paths = pickle.load(fr)\n",
    "\n",
    "picked_num = 50\n",
    "\n",
    "picked_samples_classes = [[] for _ in range(10)]\n",
    "num_cluster = 1\n",
    "clu = 0\n",
    "for cla in range(10):\n",
    "    for clu in range(num_cluster):\n",
    "        l = \"{}_{}\".format(cla, clu)\n",
    "#         print(l)\n",
    "        picked_samples_fname = \"cluster_paths/convmnist_binary_cluster/num_cluster{}_class{}_cluster{}_picked_samples.pkl\".format(num_cluster, cla, clu)\n",
    "        with open(picked_samples_fname, \"rb\") as f:\n",
    "            unpickler = pickle.Unpickler(f)\n",
    "            picked_samples = unpickler.load()\n",
    "        picked_samples_classes[cla].append(picked_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98]\n",
      "[0.99, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.97]\n",
      "[0.99, 0.98, 0.98, 0.98, 0.98, 0.98, 0.98, 0.97]\n",
      "[0.99, 0.98, 0.98, 0.98, 0.98, 0.97, 0.97]\n",
      "[0.99, 0.98, 0.98, 0.98, 0.98, 0.97]\n",
      "[0.98, 0.98, 0.98, 0.98, 0.97]\n",
      "[0.99, 0.98, 0.98, 0.97]\n",
      "[0.99, 0.99, 0.98]\n",
      "[0.99, 0.98]\n",
      "[0.99]\n",
      "0.9786666666666665\n",
      "0.9890000000000001\n"
     ]
    }
   ],
   "source": [
    "picked_num = 20\n",
    "sims_avg = np.array([0.0 for _ in range(len(paths[0]))])\n",
    "s_all = 0\n",
    "s_array = []\n",
    "num = 0\n",
    "results_simCla = []\n",
    "results_difCla = []\n",
    "for cla in range(10):\n",
    "    results = []\n",
    "    for cla2 in range(cla, 10):\n",
    "#         print(\"{}_{}\".format(cla, cla2))\n",
    "        if cla == cla2:\n",
    "            samples1 = get_random(picked_samples_classes[cla][0], picked_num, [])\n",
    "            samples2 = get_random(picked_samples_classes[cla2][0], picked_num, samples1)\n",
    "        else:\n",
    "            samples1 = get_random(picked_samples_classes[cla][0], picked_num, [])\n",
    "            samples2 = get_random(picked_samples_classes[cla2][0], picked_num, [])\n",
    "        s, sims = get_similarity(samples1, samples2)\n",
    "        results.append(round(s, 2))\n",
    "        if cla2 == cla:\n",
    "            results_simCla.append(round(s, 2))\n",
    "        else:\n",
    "            results_difCla.append(round(s, 2))\n",
    "            \n",
    "    print(results)\n",
    "    \n",
    "print(np.mean(results_difCla))\n",
    "print(np.mean(results_simCla))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
