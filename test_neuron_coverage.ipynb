{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "sys.path.append(\"LRP_path\")\n",
    "\n",
    "from innvestigator import InnvestigateModel\n",
    "from inverter_util import Flatten\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import argparse\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as Data\n",
    "from models.VGG_16 import VGG16\n",
    "# from models.vgg import vgg16_bn\n",
    "\n",
    "from models.sa_models import ConvnetMnist, ConvnetCifar\n",
    "import pickle\n",
    "from get_a_single_path import getPath\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"7\"\n",
    "\n",
    "batch_size = 32\n",
    "dataset = {}\n",
    "dataloader = {}\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "mnist_data = torchvision.datasets.MNIST(\n",
    "    root='~/.torch', train=False, download=False, transform=transform_test)\n",
    "mnist_loader = Data.DataLoader(dataset=mnist_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "cifar10_data = torchvision.datasets.CIFAR10(\n",
    "        root = './data/cifar-10',\n",
    "        train = True,\n",
    "        transform = transform_test,\n",
    "        download = False)\n",
    "cifar10_loader = Data.DataLoader(dataset=cifar10_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "dataset[\"mnist\"] = mnist_data\n",
    "dataset[\"cifar10\"] = cifar10_data\n",
    "\n",
    "dataloader[\"mnist\"] = mnist_loader\n",
    "dataloader[\"cifar10\"] = cifar10_loader\n",
    "\n",
    "models = {}\n",
    "\n",
    "model_convmnist = ConvnetMnist() \n",
    "model_convmnist.load_state_dict(torch.load(\"./trained_models/mnist_mixup_acc_99.28_ckpt.pth\")[\"net\"])\n",
    "\n",
    "model_convcifar = ConvnetCifar() \n",
    "model_convcifar.load_state_dict(torch.load(\"./trained_models/cifar_mixup_acc_90.36_ckpt.pth\")[\"net\"])\n",
    "\n",
    "model_vgg = VGG16(num_classes=10)\n",
    "model_path = \"./trained_models/model_vgg_cifar/vgg_seed32_dropout.pkl\"\n",
    "checkpoint = torch.load(model_path)\n",
    "model_vgg.load_state_dict(checkpoint)\n",
    "\n",
    "models[\"convmnist\"] = model_convmnist\n",
    "models[\"convcifar10\"] = model_convcifar\n",
    "models[\"vgg\"] = model_vgg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load adv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg mix\n",
      "Using downloaded and verified file: ./adv_data_162dCbZ-ksEh08s-njCSTDgj11uGMVwbF.pkl\n",
      "dict_keys(['timestamp', 'attack', 'model', 'layer', 'regularization_weight', 'confidence', 'adversaries', 'pert_acc', 'orig_acc', 'attack_success_rate', 'neuron_coverage_000', 'neuron_coverage_020', 'neuron_coverage_050', 'neuron_coverage_075', 'inception_score', 'fid_score_64', 'fid_score_2048', 'output_impartiality'])\n",
      "keys: manu_div4_attack:0:0:0.01\n",
      "step 0\n",
      "0.18471428571428572\n",
      "0.14217582417582417\n",
      "keys: manu_div4_attack:0:0:0.03\n",
      "step 0\n",
      "0.18985714285714286\n",
      "0.1443956043956044\n",
      "keys: manu_div4_attack:0:0:0.05\n",
      "step 0\n"
     ]
    }
   ],
   "source": [
    "## ConvnetMnist\n",
    "import torch\n",
    "from dataloader_adv_test import DatasetAdv\n",
    "from neuron_coverage import Coverager\n",
    "# convmnist 0.8, 4, 0.8\n",
    "# convcifar 0.7 7 0.9\n",
    "# vgg 0.9 7 0.9\n",
    "\n",
    "num_classes = 10\n",
    "\n",
    "bucket_m = 100\n",
    "# dic = {\n",
    "#     \"convcifar10\": \"1l0n0kqPbqcgEStCy76K9wiiO-Y4dWB35\",\n",
    "#     \"convmnist\": \"199b0k5M7OUliRzVGepMhYDRwdZ1ofuHe\",\n",
    "#     \"vgg\": \"1wpf8uNfTStBn7NkS0omhVfv2OgIlAqbU\"\n",
    "# }\n",
    "dic = {\n",
    "    \"convcifar10\": \"1CSEGygqLyPiI02B5yn0pkqySf7-pndEl\",\n",
    "    \"convcifar10_nature\": \"1CSEGygqLyPiI02B5yn0pkqySf7-pndEl\",\n",
    "    \"convmnist\": \"1ukogsUcDEr8lE-JsXr2qTd5DMEsHBWha\",\n",
    "    \"vgg\": \"162dCbZ-ksEh08s-njCSTDgj11uGMVwbF\"\n",
    "}\n",
    "model_names = [\"convmnist\", \"convcifar10\"]\n",
    "attacks = [\"pgd\", \"cw\"]\n",
    "modes = [\"mix\"]\n",
    "\n",
    "for model_name in [\"vgg\"]:\n",
    "    for mode in [\"mix\"]:\n",
    "        if model_name == \"convmnist\":\n",
    "            cluster_threshold = 0.8\n",
    "            num_cluster = 4\n",
    "            single_threshold = 0.8\n",
    "        elif model_name == \"convcifar10\":\n",
    "            cluster_threshold = 0.9\n",
    "            num_cluster = 7\n",
    "            single_threshold = 0.7\n",
    "        elif model_name == \"vgg\":\n",
    "            cluster_threshold = 0.9\n",
    "            num_cluster = 7\n",
    "            single_threshold = 0.9\n",
    "        print(model_name, mode)\n",
    "        intra = {}\n",
    "        layer_intra = {}\n",
    "\n",
    "        test_set = DatasetAdv(dic[model_name])\n",
    "        \n",
    "        fetch_func = lambda x:x[\"your_adv\"]\n",
    "\n",
    "        \n",
    "        for index, datax in enumerate(test_set):\n",
    "            covered_10 = set()\n",
    "            covered_100 = set() \n",
    "#                 print(\"index\", index)\n",
    "#             print(datax[\"key\"],datax[\"your_adv\"].shape,datax[\"your_label\"].shape,\"lbl\")\n",
    "            keys = datax[\"key\"]\n",
    "            print(\"keys:\", keys)\n",
    "#             x_test =torch.from_numpy(datax[\"your_adv\"]) \n",
    "#             y_test = torch.from_numpy(datax[\"your_label\"] )\n",
    "            x_test = datax[\"your_adv\"]\n",
    "            y_test = datax[\"your_label\"] \n",
    "#             print(x_test.shape,type(x_test))\n",
    "#             print(y_test.shape,type(y_test))\n",
    "            test_loader1=torch.torch.utils.data.DataLoader(\n",
    "                    torch.utils.data.TensorDataset(x_test, y_test),\n",
    "                    batch_size=x_test.shape[0])\n",
    "#             if index < 10:\n",
    "            for step, (x, y) in enumerate(test_loader1):\n",
    "                print(\"step\", step)\n",
    "                x = x.cuda()\n",
    "                \n",
    "                models[model_name] = models[model_name].cuda()\n",
    "                cover = Coverager(models[model_name], model_name, cluster_threshold, num_classes=num_classes, num_cluster=num_cluster)\n",
    "                covered1, total1 = cover.Intra_NPC(x, y, bucket_m, single_threshold, mode=mode, simi_soft=False)\n",
    "                covered2, total2 = cover.Layer_Intra_NPC(x, y, bucket_m, single_threshold, mode=mode, simi_soft=False)\n",
    "                covered_10 = covered_10 | covered1\n",
    "                covered_100 = covered_100 | covered2 \n",
    "#                     print(cover.get_simi(x, y, bucket_m, single_threshold, mode=mode, simi_soft=False))\n",
    "            intra[keys] = len(covered_10) / total1\n",
    "            layer_intra[keys] = len(covered_100) / total2\n",
    "            print(intra[keys])\n",
    "            print(layer_intra[keys])\n",
    "        save_filename_10 = \"./coverage_results/{}_Our_10_{}\".format(mode, dic[model_name])\n",
    "        save_filename_100 = \"./coverage_results/{}_Our_100_{}\".format(mode, dic[model_name])\n",
    "        np.save(save_filename_10, intra) \n",
    "        np.save(save_filename_100, layer_intra) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_adv_test import DatasetAdv\n",
    "from neuron_coverage import Coverager\n",
    "\n",
    "single_threshold = 0.8\n",
    "num_classes = 10\n",
    "num_cluster = 7\n",
    "bucket_m = 100\n",
    "dic = {\n",
    "    \"convcifar10\": \"1Gc5n0UNRmJ2v9WjWZJ9JstmIoP3cWiFw\",\n",
    "    \"convmnist\": \"12DdlhFwJQJl3W2gNbxaL9z9rIqf60mrD\",\n",
    "}\n",
    "model_names = [\"convmnist\", \"convcifar10\"]\n",
    "attacks = [\"pgd\", \"cw\"]\n",
    "modes = [\"right\", \"wrong\", \"mix\"]\n",
    "\n",
    "for model_name in [\"convcifar10\", \"convmnist\"]:\n",
    "    for mode in [\"mix\"]:\n",
    "        print(model_name, mode)\n",
    "        intra = {}\n",
    "        layer_intra = {}\n",
    "\n",
    "        test_set = DatasetAdv(dic[model_name])\n",
    "        \n",
    "        fetch_func = lambda x:x[\"your_adv\"]\n",
    "\n",
    "        \n",
    "        for index, datax in enumerate(test_set):\n",
    "            covered_10 = set()\n",
    "            covered_100 = set() \n",
    "#                 print(\"index\", index)\n",
    "#             print(datax[\"key\"],datax[\"your_adv\"].shape,datax[\"your_label\"].shape,\"lbl\")\n",
    "            keys = datax[\"key\"]\n",
    "            print(\"keys:\", keys)\n",
    "#             x_test =torch.from_numpy(datax[\"your_adv\"]) \n",
    "#             y_test = torch.from_numpy(datax[\"your_label\"] )\n",
    "            x_test = datax[\"your_adv\"]\n",
    "            y_test = datax[\"your_label\"] \n",
    "#             print(x_test.shape,type(x_test))\n",
    "#             print(y_test.shape,type(y_test))\n",
    "            test_loader1=torch.torch.utils.data.DataLoader(\n",
    "                    torch.utils.data.TensorDataset(x_test, y_test),\n",
    "                    batch_size=x_test.shape[0])\n",
    "#             if index < 10:\n",
    "            for step, (x, y) in enumerate(test_loader1):\n",
    "                print(\"step\", step)\n",
    "                x = x.cuda()\n",
    "                if model_name == \"convmnist\":\n",
    "                    cluster_threshold = 0.4\n",
    "                else:\n",
    "                    cluster_threshold = 0.9\n",
    "                models[model_name] = models[model_name].cuda()\n",
    "                cover = Coverager(models[model_name], model_name, cluster_threshold, num_classes=num_classes, num_cluster=num_cluster)\n",
    "                covered1, total1 = cover.Intra_NPC(x, y, bucket_m, single_threshold, mode=mode, simi_soft=False)\n",
    "                covered2, total2 = cover.Layer_Intra_NPC(x, y, bucket_m, single_threshold, mode=mode, simi_soft=False)\n",
    "                covered_10 = covered_10 | covered1\n",
    "                covered_100 = covered_100 | covered2 \n",
    "#                     print(cover.get_simi(x, y, bucket_m, single_threshold, mode=mode, simi_soft=False))\n",
    "            intra[keys] = len(covered_10) / total1\n",
    "            layer_intra[keys] = len(covered_100) / total2\n",
    "            print(intra[keys])\n",
    "            print(layer_intra[keys])\n",
    "        save_filename_10 = \"./coverage_results/{}_Our_10_{}\".format(mode, dic[model_name])\n",
    "        save_filename_100 = \"./coverage_results/{}_Our_100_{}\".format(mode, dic[model_name])\n",
    "        np.save(save_filename_10, intra) \n",
    "        np.save(save_filename_100, layer_intra) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_test_data = torchvision.datasets.CIFAR10(\n",
    "        root = './data/cifar-10',\n",
    "        train = False,\n",
    "        transform = transform_test,\n",
    "        download = False)\n",
    "cifar10_test_loader = Data.DataLoader(dataset=cifar10_test_data, batch_size=batch_size, shuffle=False)\n",
    "mnist_test_data = torchvision.datasets.MNIST(\n",
    "    root='~/.torch', train=False, download=False, transform=transform_test)\n",
    "mnist_test_loader = Data.DataLoader(dataset=mnist_test_data, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "from dataloader_adv_test import DatasetAdv\n",
    "from neuron_coverage import Coverager\n",
    "\n",
    "width_threshold = 0.4\n",
    "single_threshold = 0.8\n",
    "num_classes = 10\n",
    "num_cluster = 1\n",
    "bucket_m = 5\n",
    "dic = {\n",
    "    \"convmnist_pgd\": \"1hc_aj908k7_Zs2L4TsaWYENG-GwtdJe2\",\n",
    "    \"convmnist_cw\": \"1aRN20FXhxvWqsIQTdDSNwei_jYSx5S7a\",\n",
    "    \"convcifar10_pgd\": \"1nhWO0VT131_9e5ubgzs343EhM9Ru0UvY\",\n",
    "    \"convcifar10_cw\": \"1MrRngrHDuSm2fEd044mNktkZtDSM33U4\",\n",
    "    \"vgg_pgd\": \"1Gm926_p5_bvhgfDdlQmmV9lUCmjsF5Ft\",\n",
    "    \"vgg_cw\": \"1-X1d-qaYGpUacej9McI5DOq20dDOk9ia\",\n",
    "}\n",
    "model_names = [\"convmnist\", \"convcifar10\", \"vgg\"]\n",
    "attacks = [\"pgd\", \"cw\"]\n",
    "modes = [\"right\", \"wrong\", \"mix\"]\n",
    "\n",
    "for model_name in [\"convmnist\"]:\n",
    "    for attack in [\"cw\"]:\n",
    "        for mode in [\"right\", \"wrong\"]:\n",
    "            print(\"mode:\", mode)\n",
    "            for step, (x, y) in enumerate(mnist_test_loader):\n",
    "                if step >= 30:\n",
    "                    break\n",
    "                x = x.cuda()\n",
    "                models[model_name] = models[model_name].cuda()\n",
    "                cover = Coverager(models[model_name], model_name, width_threshold, num_classes=num_classes, num_cluster=num_cluster)\n",
    "#                         intra[keys] = cover.Intra_NPC(x, y, bucket_m, mode=mode, simi_soft=True)\n",
    "#                         layer_intra[keys] = cover.Layer_Intra_NPC(x, y, bucket_m, mode=mode, simi_soft=True)\n",
    "                print(cover.get_simi(x, y, bucket_m, single_threshold=0.8, mode=mode, simi_soft=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convcifar10 mix\n",
      "Using downloaded and verified file: ./adv_data_1Gc5n0UNRmJ2v9WjWZJ9JstmIoP3cWiFw.pkl\n",
      "dict_keys(['timestamp', 'attack', 'model', 'layer', 'regularization_weight', 'confidence', 'adversaries', 'pert_acc', 'orig_acc', 'attack_success_rate', 'neuron_coverage_000', 'neuron_coverage_020', 'neuron_coverage_050', 'neuron_coverage_075', 'inception_score', 'fid_score_64', 'fid_score_2048', 'output_impartiality'])\n",
      "keys: manu_div4_attack:0:0:0\n",
      "step 0\n",
      "0.182\n",
      "0.19951785714285714\n",
      "keys: manu_div4_attack:0:0:4\n",
      "step 0\n",
      "0.19042857142857142\n",
      "0.20235714285714285\n",
      "keys: manu_div4_attack:0:0:8\n",
      "step 0\n",
      "0.19714285714285715\n",
      "0.20491071428571428\n",
      "keys: manu_div4_attack:0:0:12\n",
      "step 0\n",
      "0.2\n",
      "0.20760714285714285\n",
      "keys: manu_div4_attack:0:0:16\n",
      "step 0\n",
      "0.2037142857142857\n",
      "0.2095357142857143\n",
      "keys: manu_div4_attack:0:0:20\n",
      "step 0\n",
      "0.20814285714285713\n",
      "0.21182142857142858\n",
      "keys: manu_div4_attack:0:0:24\n",
      "step 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-beb662751087>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     49\u001b[0m                 \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mcover\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCoverager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcluster_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cluster\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m                 \u001b[0mcovered1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcover\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIntra_NPC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimi_soft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m                 \u001b[0mcovered2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcover\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayer_Intra_NPC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket_m\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msingle_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msimi_soft\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m                 \u001b[0mcovered_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcovered_10\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mcovered1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme/litl/CriticalPath/neuron_coverage.py\u001b[0m in \u001b[0;36mIntra_NPC\u001b[0;34m(self, X, Y, bucket_m, threshold, mode, simi_soft)\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mval_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mpath_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme/litl/CriticalPath/get_a_single_path.py\u001b[0m in \u001b[0;36mgetPath\u001b[0;34m(data, model, width_threshold, other_label, target)\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelev\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpick_neurons_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/nvme/litl/CriticalPath/get_a_single_path.py\u001b[0m in \u001b[0;36mpick_neurons_layer\u001b[0;34m(relev, threshold, last)\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                         \u001b[0msum_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/critical/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cluster_threshold = 0.4\n",
    "single_threshold = 0.8\n",
    "num_classes = 10\n",
    "num_cluster = 7\n",
    "bucket_m = 100\n",
    "dic = {\n",
    "    \"convcifar10\": \"1Gc5n0UNRmJ2v9WjWZJ9JstmIoP3cWiFw\",\n",
    "    \"convmnist\": \"12DdlhFwJQJl3W2gNbxaL9z9rIqf60mrD\",\n",
    "}\n",
    "model_names = [\"convmnist\", \"convcifar10\"]\n",
    "attacks = [\"pgd\", \"cw\"]\n",
    "modes = [\"right\", \"wrong\", \"mix\"]\n",
    "\n",
    "for model_name in [\"convcifar10\", \"convmnist\"]:\n",
    "    for mode in [\"mix\"]:\n",
    "        print(model_name, mode)\n",
    "        intra = {}\n",
    "        layer_intra = {}\n",
    "\n",
    "        test_set = DatasetAdv(dic[model_name])\n",
    "        \n",
    "        fetch_func = lambda x:x[\"your_adv\"]\n",
    "\n",
    "        \n",
    "        for index, datax in enumerate(test_set):\n",
    "            covered_10 = set()\n",
    "            covered_100 = set() \n",
    "#                 print(\"index\", index)\n",
    "#             print(datax[\"key\"],datax[\"your_adv\"].shape,datax[\"your_label\"].shape,\"lbl\")\n",
    "            keys = datax[\"key\"]\n",
    "            print(\"keys:\", keys)\n",
    "#             x_test =torch.from_numpy(datax[\"your_adv\"]) \n",
    "#             y_test = torch.from_numpy(datax[\"your_label\"] )\n",
    "            x_test = datax[\"your_adv\"]\n",
    "            y_test = datax[\"your_label\"] \n",
    "#             print(x_test.shape,type(x_test))\n",
    "#             print(y_test.shape,type(y_test))\n",
    "            test_loader1=torch.torch.utils.data.DataLoader(\n",
    "                    torch.utils.data.TensorDataset(x_test, y_test),\n",
    "                    batch_size=x_test.shape[0])\n",
    "#             if index < 10:\n",
    "            for step, (x, y) in enumerate(test_loader1):\n",
    "                print(\"step\", step)\n",
    "                x = x.cuda()\n",
    "                if model_name == \"convmnist\":\n",
    "                    cluster_threshold = 0.4\n",
    "                else:\n",
    "                    cluster_threshold = 0.9\n",
    "                models[model_name] = models[model_name].cuda()\n",
    "                cover = Coverager(models[model_name], model_name, cluster_threshold, num_classes=num_classes, num_cluster=num_cluster)\n",
    "                covered1, total1 = cover.Intra_NPC(x, y, bucket_m, single_threshold, mode=mode, simi_soft=False)\n",
    "                covered2, total2 = cover.Layer_Intra_NPC(x, y, bucket_m, single_threshold, mode=mode, simi_soft=False)\n",
    "                covered_10 = covered_10 | covered1\n",
    "                covered_100 = covered_100 | covered2 \n",
    "#                     print(cover.get_simi(x, y, bucket_m, single_threshold, mode=mode, simi_soft=False))\n",
    "            intra[keys] = len(covered_10) / total1\n",
    "            layer_intra[keys] = len(covered_100) / total2\n",
    "            print(intra[keys])\n",
    "            print(layer_intra[keys])\n",
    "        save_filename_10 = \"./coverage_results/{}_Our_10_{}\".format(mode, dic[model_name])\n",
    "        save_filename_100 = \"./coverage_results/{}_Our_100_{}\".format(mode, dic[model_name])\n",
    "        np.save(save_filename_10, intra) \n",
    "        np.save(save_filename_100, layer_intra) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the path: test of a single input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = dataloader[\"mnist\"]\n",
    "model1 = models[\"convmnist\"]\n",
    "width_threshold = 0.8\n",
    "\n",
    "for i, (data, target) in enumerate(images):\n",
    "    data1 = data\n",
    "    path = getPath(data, model1, width_threshold)\n",
    "#     print(path)\n",
    "    break\n",
    "\n",
    "images = dataloader[\"cifar10\"]\n",
    "model2 = models[\"convcifar10\"]\n",
    "width_threshold = 0.8\n",
    "for i, (data, target) in enumerate(images):\n",
    "    data2 = data\n",
    "    path = getPath(data, model2, width_threshold)\n",
    "#     print(path)\n",
    "    break\n",
    "\n",
    "images = dataloader[\"cifar10\"]\n",
    "model3 = models[\"vgg\"]\n",
    "width_threshold = 0.8\n",
    "for i, (data, target) in enumerate(images):\n",
    "    data3 = data\n",
    "    path = getPath(data, model3, width_threshold)\n",
    "#     print(path)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test of neuron coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "from neuron_coverage import Coverager\n",
    "\n",
    "width_threshold = 0.8\n",
    "num_classes = 10\n",
    "num_cluster = 10\n",
    "bucket_m = 10\n",
    "\n",
    "from neuron_coverage import Coverager\n",
    "cover = Coverager(model1, \"convmnist\", width_threshold, num_classes=num_classes, num_cluster=num_cluster)\n",
    "X = dataset[\"mnist\"][50][0].unsqueeze(0)\n",
    "print(cover.Intra_NPC(X, bucket_m))\n",
    "print(cover.Layer_Intra_NPC(X, bucket_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "cover = Coverager(model2, \"convcifar10\", width_threshold, num_classes=num_classes, num_cluster=num_cluster)\n",
    "X = dataset[\"cifar10\"][50][0].unsqueeze(0)\n",
    "print(cover.Intra_NPC(X, bucket_m))\n",
    "print(cover.Layer_Intra_NPC(X, bucket_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01\n",
      "0.01\n"
     ]
    }
   ],
   "source": [
    "cover = Coverager(model3, \"vgg\", width_threshold, num_classes=num_classes, num_cluster=num_cluster)\n",
    "X = dataset[\"cifar10\"][50][0].unsqueeze(0)\n",
    "print(cover.Intra_NPC(X, bucket_m))\n",
    "print(cover.Layer_Intra_NPC(X, bucket_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.515\n",
      "0.639\n"
     ]
    }
   ],
   "source": [
    "cover = Coverager(model1, \"convmnist\", width_threshold, num_classes=num_classes, num_cluster=num_cluster)\n",
    "print(cover.Intra_NPC(data1, bucket_m))\n",
    "print(cover.Layer_Intra_NPC(data1, bucket_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.386\n",
      "0.550875\n"
     ]
    }
   ],
   "source": [
    "cover = Coverager(model2, \"convcifar10\", width_threshold, num_classes=num_classes, num_cluster=num_cluster)\n",
    "print(cover.Intra_NPC(data2, bucket_m))\n",
    "print(cover.Layer_Intra_NPC(data2, bucket_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.376\n",
      "0.5511538461538461\n"
     ]
    }
   ],
   "source": [
    "from neuron_coverage import Coverager\n",
    "\n",
    "width_threshold = 0.8\n",
    "num_classes = 10\n",
    "num_cluster = 10\n",
    "bucket_m = 10\n",
    "\n",
    "cover = Coverager(model3, \"vgg\", width_threshold, num_classes=num_classes, num_cluster=num_cluster)\n",
    "print(cover.Intra_NPC(data3, bucket_m))\n",
    "print(cover.Layer_Intra_NPC(data3, bucket_m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [1, 2, 3]\n",
    "np.mean(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
